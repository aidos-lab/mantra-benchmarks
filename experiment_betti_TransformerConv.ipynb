{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:47:32.798261Z",
     "start_time": "2024-04-25T17:47:19.035622Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, ImbalancedSampler\n",
    "from torch_geometric.transforms import FaceToEdge, OneHotDegree\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from mantra.simplicial import SimplicialDataset\n",
    "from mantra.transforms import (\n",
    "    TriangulationToFaceTransform,\n",
    "    OrientableToClassTransform,\n",
    "    DegreeTransform,\n",
    ")\n",
    "from validation.validate_homology import validate_betti_numbers\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: SimplicialDataset(712):\n",
      "====================\n",
      "Number of graphs: 712\n",
      "Number of features: 9\n",
      "Number of classes: 2\n",
      "\n",
      "Data(dimension=[1], n_vertices=[1], torsion_coefficients=[3], betti_numbers=[3], orientable=[1], genus=[1], name='S^2', face=[3, 4], edge_index=[2, 12], x=[4, 9], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 4\n",
      "Number of edges: 12\n",
      "Average node degree: 3.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "=============================================================\n",
      "Number of orientable Manifolds: 193\n",
      "Number of non-orientable Manifolds: 519\n",
      "Percentage: 0.27, 0.73\n"
     ]
    }
   ],
   "source": [
    "tr = transforms.Compose(\n",
    "    [\n",
    "        TriangulationToFaceTransform(),\n",
    "        FaceToEdge(remove_faces=False),\n",
    "        DegreeTransform(),\n",
    "        OrientableToClassTransform(),\n",
    "        OneHotDegree(max_degree=8,cat=False)\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = SimplicialDataset(root=\"./data\", transform=tr)\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"Dataset: {dataset}:\")\n",
    "print(\"====================\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print(\"=============================================================\")\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f\"Number of nodes: {len(data.x)}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Average node degree: {data.num_edges / len(data.x):.2f}\")\n",
    "print(f\"Has isolated nodes: {data.has_isolated_nodes()}\")\n",
    "print(f\"Has self-loops: {data.has_self_loops()}\")\n",
    "print(f\"Is undirected: {data.is_undirected()}\")\n",
    "\n",
    "print(\"=============================================================\")\n",
    "print(f\"Number of orientable Manifolds: {sum(dataset.orientable)}\")\n",
    "print(\n",
    "    f\"Number of non-orientable Manifolds: {len(dataset) - sum(dataset.orientable)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percentage: {sum(dataset.orientable) / len(dataset):.2f}, {(len(dataset) - sum(dataset.orientable)) / len(dataset):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.betti_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 562\n",
      "Number of test graphs: 150\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:-150]\n",
    "test_dataset = dataset[-150:]\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_dataset)}\")\n",
    "print(f\"Number of test graphs: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=10)#,sampler=ImbalancedSampler(train_dataset))\n",
    "test_loader = DataLoader(test_dataset,batch_size=10)\n",
    "\n",
    "\n",
    "for batch in train_loader:\n",
    "    break\n",
    "\n",
    "batch.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0788, -0.0744, -0.0329],\n",
      "        [ 0.1500, -0.0435, -0.1150],\n",
      "        [ 0.1908,  0.1661, -0.0821],\n",
      "        [ 0.1692,  0.0347, -0.2018],\n",
      "        [-0.1191, -0.0769,  0.0184],\n",
      "        [ 0.2564,  0.0817, -0.2506],\n",
      "        [-0.0386, -0.1109, -0.0483],\n",
      "        [ 0.2014, -0.0658,  0.0422],\n",
      "        [ 0.2608, -0.0205, -0.1961],\n",
      "        [ 0.1721,  0.1232, -0.2513]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from operator import concat\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TAGConv,TransformerConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = TransformerConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = TransformerConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = TransformerConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 3)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(batch.x, batch.edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, batch.edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, batch.edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch.batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 14.3012, Test Acc: 3.9595\n",
      "Epoch: 002, Train Acc: 7.9209, Test Acc: 2.2424\n",
      "Epoch: 003, Train Acc: 7.3249, Test Acc: 2.1451\n",
      "Epoch: 004, Train Acc: 7.0863, Test Acc: 2.0972\n",
      "Epoch: 005, Train Acc: 6.5136, Test Acc: 1.9514\n",
      "Epoch: 006, Train Acc: 5.7232, Test Acc: 1.6731\n",
      "Epoch: 007, Train Acc: 5.6288, Test Acc: 1.6629\n",
      "Epoch: 008, Train Acc: 5.3735, Test Acc: 1.6019\n",
      "Epoch: 009, Train Acc: 5.5434, Test Acc: 1.6216\n",
      "Epoch: 010, Train Acc: 5.0546, Test Acc: 1.4855\n",
      "Epoch: 011, Train Acc: 5.0977, Test Acc: 1.4528\n",
      "Epoch: 012, Train Acc: 5.1413, Test Acc: 1.5387\n",
      "Epoch: 013, Train Acc: 5.0282, Test Acc: 1.4862\n",
      "Epoch: 014, Train Acc: 4.5230, Test Acc: 1.3564\n",
      "Epoch: 015, Train Acc: 4.5798, Test Acc: 1.3817\n",
      "Epoch: 016, Train Acc: 4.7982, Test Acc: 1.4428\n",
      "Epoch: 017, Train Acc: 5.1819, Test Acc: 1.5367\n",
      "Epoch: 018, Train Acc: 5.0257, Test Acc: 1.5190\n",
      "Epoch: 019, Train Acc: 4.4559, Test Acc: 1.3445\n",
      "Epoch: 020, Train Acc: 4.2240, Test Acc: 1.2602\n",
      "Epoch: 021, Train Acc: 4.5640, Test Acc: 1.3807\n",
      "Epoch: 022, Train Acc: 4.7071, Test Acc: 1.4230\n",
      "Epoch: 023, Train Acc: 4.5142, Test Acc: 1.3686\n",
      "Epoch: 024, Train Acc: 4.2264, Test Acc: 1.2772\n",
      "Epoch: 025, Train Acc: 4.0160, Test Acc: 1.2058\n",
      "Epoch: 026, Train Acc: 4.4284, Test Acc: 1.3742\n",
      "Epoch: 027, Train Acc: 4.1022, Test Acc: 1.2546\n",
      "Epoch: 028, Train Acc: 4.1525, Test Acc: 1.2840\n",
      "Epoch: 029, Train Acc: 4.2535, Test Acc: 1.3084\n",
      "Epoch: 030, Train Acc: 4.3463, Test Acc: 1.3431\n",
      "Epoch: 031, Train Acc: 3.9852, Test Acc: 1.2140\n",
      "Epoch: 032, Train Acc: 4.1442, Test Acc: 1.2774\n",
      "Epoch: 033, Train Acc: 4.0151, Test Acc: 1.2465\n",
      "Epoch: 034, Train Acc: 4.9950, Test Acc: 1.5060\n",
      "Epoch: 035, Train Acc: 3.9615, Test Acc: 1.2502\n",
      "Epoch: 036, Train Acc: 4.5018, Test Acc: 1.4480\n",
      "Epoch: 037, Train Acc: 3.8346, Test Acc: 1.1762\n",
      "Epoch: 038, Train Acc: 3.7178, Test Acc: 1.1769\n",
      "Epoch: 039, Train Acc: 3.8979, Test Acc: 1.2257\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(out, torch.tensor(data.betti_numbers,dtype=torch.float))  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    losses = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data)\n",
    "        \n",
    "        losses += criterion(out, torch.tensor(data.betti_numbers,dtype=torch.float))\n",
    "    return losses\n",
    "\n",
    "\n",
    "for epoch in range(1, 40):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(\n",
    "        f\"Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted incorrect 395\n",
      "predicted incorrect 55\n",
      "percentage correct 0.8777777777777778\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "losses = 0\n",
    "y_hat = []\n",
    "y = []\n",
    "for data in test_loader:  # Iterate in batches over the training/test dataset.\n",
    "    out = model(data)\n",
    "    y_hat.append(out.round().long())\n",
    "    y.append(torch.tensor(data.betti_numbers))\n",
    "\n",
    "y_hat = torch.vstack(y_hat)\n",
    "y = torch.vstack(y)\n",
    "\n",
    "\n",
    "incorrect = torch.count_nonzero(y-y_hat!=0).item()\n",
    "correct = torch.count_nonzero(y-y_hat==0).item()\n",
    "\n",
    "print(\"predicted incorrect\",correct)\n",
    "print(\"predicted incorrect\",incorrect)\n",
    "print(\"percentage correct\", correct / (correct + incorrect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
