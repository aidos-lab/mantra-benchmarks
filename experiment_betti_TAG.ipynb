{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:47:32.798261Z",
     "start_time": "2024-04-25T17:47:19.035622Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, ImbalancedSampler\n",
    "from torch_geometric.transforms import FaceToEdge, OneHotDegree\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from mantra.simplicial import SimplicialDataset\n",
    "from mantra.transforms import (\n",
    "    TriangulationToFaceTransform,\n",
    "    OrientableToClassTransform,\n",
    "    DegreeTransform,\n",
    ")\n",
    "from validation.validate_homology import validate_betti_numbers\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: SimplicialDataset(712):\n",
      "====================\n",
      "Number of graphs: 712\n",
      "Number of features: 9\n",
      "Number of classes: 2\n",
      "\n",
      "Data(dimension=[1], n_vertices=[1], torsion_coefficients=[3], betti_numbers=[3], orientable=[1], genus=[1], name='S^2', face=[3, 4], edge_index=[2, 12], x=[4, 9], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 4\n",
      "Number of edges: 12\n",
      "Average node degree: 3.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "=============================================================\n",
      "Number of orientable Manifolds: 193\n",
      "Number of non-orientable Manifolds: 519\n",
      "Percentage: 0.27, 0.73\n"
     ]
    }
   ],
   "source": [
    "tr = transforms.Compose(\n",
    "    [\n",
    "        TriangulationToFaceTransform(),\n",
    "        FaceToEdge(remove_faces=False),\n",
    "        DegreeTransform(),\n",
    "        OrientableToClassTransform(),\n",
    "        OneHotDegree(max_degree=8, cat=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = SimplicialDataset(root=\"./data\", transform=tr)\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"Dataset: {dataset}:\")\n",
    "print(\"====================\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print(\"=============================================================\")\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f\"Number of nodes: {len(data.x)}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Average node degree: {data.num_edges / len(data.x):.2f}\")\n",
    "print(f\"Has isolated nodes: {data.has_isolated_nodes()}\")\n",
    "print(f\"Has self-loops: {data.has_self_loops()}\")\n",
    "print(f\"Is undirected: {data.is_undirected()}\")\n",
    "\n",
    "print(\"=============================================================\")\n",
    "print(f\"Number of orientable Manifolds: {sum(dataset.orientable)}\")\n",
    "print(\n",
    "    f\"Number of non-orientable Manifolds: {len(dataset) - sum(dataset.orientable)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percentage: {sum(dataset.orientable) / len(dataset):.2f}, {(len(dataset) - sum(dataset.orientable)) / len(dataset):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.betti_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 562\n",
      "Number of test graphs: 150\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:-150]\n",
    "test_dataset = dataset[-150:]\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_dataset)}\")\n",
    "print(f\"Number of test graphs: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=10\n",
    ")  # ,sampler=ImbalancedSampler(train_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=10)\n",
    "\n",
    "\n",
    "for batch in train_loader:\n",
    "    break\n",
    "\n",
    "batch.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0592, -0.0860,  0.0107],\n",
      "        [-0.0745, -0.0838, -0.0963],\n",
      "        [-0.1234, -0.1174,  0.0508],\n",
      "        [-0.2945, -0.0624,  0.3497],\n",
      "        [-0.3387, -0.0551, -0.0335],\n",
      "        [-0.1517, -0.1775, -0.2044],\n",
      "        [-0.1485, -0.0703, -0.0104],\n",
      "        [-0.1371, -0.1050, -0.0641],\n",
      "        [-0.0389, -0.2190,  0.0169],\n",
      "        [ 0.0023, -0.2771, -0.1588]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from operator import concat\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TAGConv, TransformerConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = TAGConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = TAGConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = TAGConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 3)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(batch.x, batch.edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, batch.edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, batch.edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch.batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 6.5337, Test Acc: 2.0014\n",
      "Epoch: 002, Train Acc: 6.1711, Test Acc: 1.7780\n",
      "Epoch: 003, Train Acc: 5.5158, Test Acc: 1.5298\n",
      "Epoch: 004, Train Acc: 5.0714, Test Acc: 1.4182\n",
      "Epoch: 005, Train Acc: 7.9687, Test Acc: 2.0118\n",
      "Epoch: 006, Train Acc: 5.9958, Test Acc: 1.6171\n",
      "Epoch: 007, Train Acc: 4.3281, Test Acc: 1.3416\n",
      "Epoch: 008, Train Acc: 4.8488, Test Acc: 1.4623\n",
      "Epoch: 009, Train Acc: 4.3541, Test Acc: 1.3209\n",
      "Epoch: 010, Train Acc: 4.5998, Test Acc: 1.2991\n",
      "Epoch: 011, Train Acc: 4.9841, Test Acc: 1.4021\n",
      "Epoch: 012, Train Acc: 4.2027, Test Acc: 1.3458\n",
      "Epoch: 013, Train Acc: 4.1259, Test Acc: 1.2443\n",
      "Epoch: 014, Train Acc: 4.9470, Test Acc: 1.5142\n",
      "Epoch: 015, Train Acc: 4.3742, Test Acc: 1.3832\n",
      "Epoch: 016, Train Acc: 4.3983, Test Acc: 1.3189\n",
      "Epoch: 017, Train Acc: 4.8632, Test Acc: 1.4811\n",
      "Epoch: 018, Train Acc: 4.1164, Test Acc: 1.2966\n",
      "Epoch: 019, Train Acc: 4.2895, Test Acc: 1.3772\n",
      "Epoch: 020, Train Acc: 4.3439, Test Acc: 1.4044\n",
      "Epoch: 021, Train Acc: 4.5521, Test Acc: 1.4183\n",
      "Epoch: 022, Train Acc: 4.1032, Test Acc: 1.3653\n",
      "Epoch: 023, Train Acc: 7.5456, Test Acc: 1.5576\n",
      "Epoch: 024, Train Acc: 5.2212, Test Acc: 1.5423\n",
      "Epoch: 025, Train Acc: 4.2803, Test Acc: 1.2952\n",
      "Epoch: 026, Train Acc: 4.8403, Test Acc: 1.4016\n",
      "Epoch: 027, Train Acc: 5.2088, Test Acc: 1.4992\n",
      "Epoch: 028, Train Acc: 4.1632, Test Acc: 1.2780\n",
      "Epoch: 029, Train Acc: 4.1269, Test Acc: 1.3689\n",
      "Epoch: 030, Train Acc: 4.8322, Test Acc: 1.4433\n",
      "Epoch: 031, Train Acc: 4.7486, Test Acc: 1.4451\n",
      "Epoch: 032, Train Acc: 3.9849, Test Acc: 1.2616\n",
      "Epoch: 033, Train Acc: 3.9689, Test Acc: 1.3034\n",
      "Epoch: 034, Train Acc: 4.3163, Test Acc: 1.3400\n",
      "Epoch: 035, Train Acc: 4.1944, Test Acc: 1.3585\n",
      "Epoch: 036, Train Acc: 4.7218, Test Acc: 1.5358\n",
      "Epoch: 037, Train Acc: 4.0876, Test Acc: 1.3294\n",
      "Epoch: 038, Train Acc: 4.2680, Test Acc: 1.4031\n",
      "Epoch: 039, Train Acc: 4.0934, Test Acc: 1.3362\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(\n",
    "            out, torch.tensor(data.betti_numbers, dtype=torch.float)\n",
    "        )  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    losses = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data)\n",
    "\n",
    "        losses += criterion(\n",
    "            out, torch.tensor(data.betti_numbers, dtype=torch.float)\n",
    "        )\n",
    "    return losses\n",
    "\n",
    "\n",
    "for epoch in range(1, 40):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(\n",
    "        f\"Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted incorrect 391\n",
      "predicted incorrect 59\n",
      "percentage correct 0.8688888888888889\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "losses = 0\n",
    "y_hat = []\n",
    "y = []\n",
    "for data in test_loader:  # Iterate in batches over the training/test dataset.\n",
    "    out = model(data)\n",
    "    y_hat.append(out.round().long())\n",
    "    y.append(torch.tensor(data.betti_numbers))\n",
    "\n",
    "y_hat = torch.vstack(y_hat)\n",
    "y = torch.vstack(y)\n",
    "\n",
    "\n",
    "incorrect = torch.count_nonzero(y - y_hat != 0).item()\n",
    "correct = torch.count_nonzero(y - y_hat == 0).item()\n",
    "\n",
    "print(\"predicted incorrect\", correct)\n",
    "print(\"predicted incorrect\", incorrect)\n",
    "print(\"percentage correct\", correct / (correct + incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
