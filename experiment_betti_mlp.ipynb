{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:47:32.798261Z",
     "start_time": "2024-04-25T17:47:19.035622Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, ImbalancedSampler\n",
    "from torch_geometric.transforms import FaceToEdge, OneHotDegree\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from mantra.simplicial import SimplicialDataset\n",
    "from mantra.transforms import (\n",
    "    TriangulationToFaceTransform,\n",
    "    OrientableToClassTransform,\n",
    "    DegreeTransform,\n",
    ")\n",
    "from validation.validate_homology import validate_betti_numbers\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: SimplicialDataset(712):\n",
      "====================\n",
      "Number of graphs: 712\n",
      "Number of features: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ernst\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch_geometric\\data\\storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'betti_numbers', 'dimension', 'n_vertices', 'name', 'torsion_coefficients', 'face', 'genus', 'orientable'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "\n",
      "Data(dimension=[1], n_vertices=[1], torsion_coefficients=[3], betti_numbers=[3], orientable=[1], genus=[1], name='S^2', face=[3, 4], edge_index=[2, 12], x=[4, 9], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 4\n",
      "Number of edges: 12\n",
      "Average node degree: 3.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "=============================================================\n",
      "Number of orientable Manifolds: 193\n",
      "Number of non-orientable Manifolds: 519\n",
      "Percentage: 0.27, 0.73\n"
     ]
    }
   ],
   "source": [
    "tr = transforms.Compose(\n",
    "    [\n",
    "        TriangulationToFaceTransform(),\n",
    "        FaceToEdge(remove_faces=False),\n",
    "        DegreeTransform(),\n",
    "        OrientableToClassTransform(),\n",
    "        OneHotDegree(max_degree=8,cat=False)\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = SimplicialDataset(root=\"./data\", transform=tr)\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"Dataset: {dataset}:\")\n",
    "print(\"====================\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print(\"=============================================================\")\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f\"Number of nodes: {len(data.x)}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Average node degree: {data.num_edges / len(data.x):.2f}\")\n",
    "print(f\"Has isolated nodes: {data.has_isolated_nodes()}\")\n",
    "print(f\"Has self-loops: {data.has_self_loops()}\")\n",
    "print(f\"Is undirected: {data.is_undirected()}\")\n",
    "\n",
    "print(\"=============================================================\")\n",
    "print(f\"Number of orientable Manifolds: {sum(dataset.orientable)}\")\n",
    "print(\n",
    "    f\"Number of non-orientable Manifolds: {len(dataset) - sum(dataset.orientable)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percentage: {sum(dataset.orientable) / len(dataset):.2f}, {(len(dataset) - sum(dataset.orientable)) / len(dataset):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.betti_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 562\n",
      "Number of test graphs: 150\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:-150]\n",
    "test_dataset = dataset[-150:]\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_dataset)}\")\n",
    "print(f\"Number of test graphs: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=10)#,sampler=ImbalancedSampler(train_dataset))\n",
    "test_loader = DataLoader(test_dataset,batch_size=10)\n",
    "\n",
    "\n",
    "for batch in train_loader:\n",
    "    break\n",
    "\n",
    "batch.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2394, -0.3322,  0.7674],\n",
      "        [-1.1591, -0.6497,  0.7996],\n",
      "        [-1.0816, -0.3613,  0.6788],\n",
      "        [-1.1017, -0.5386,  0.8528],\n",
      "        [-1.2463, -0.3314,  0.7317],\n",
      "        [-1.2013, -0.5507,  0.7876],\n",
      "        [-1.0896, -0.5982,  0.8156],\n",
      "        [-1.1058, -0.6580,  0.8609],\n",
      "        [-1.1820, -0.3744,  0.8095],\n",
      "        [-1.2314, -0.4554,  0.7725]], grad_fn=<CppNode<class SegmentSumCOO>>)\n"
     ]
    }
   ],
   "source": [
    "from operator import concat\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TAGConv,TransformerConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_scatter import segment_coo\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class PermInvariant(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # torch.manual_seed(12345)\n",
    "        self.classification = nn.Sequential( \n",
    "            nn.Linear(dataset.num_node_features,hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels,hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels,3)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = self.classification(batch.x)\n",
    "        # print(batch.x)\n",
    "        # print(x)\n",
    "        return segment_coo(x,batch.batch,reduce=\"sum\")\n",
    "\n",
    "\n",
    "model = PermInvariant(hidden_channels=64)\n",
    "print(model(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 6.9451, Test Acc: 1.6976\n",
      "Epoch: 002, Train Acc: 6.9317, Test Acc: 1.6716\n",
      "Epoch: 003, Train Acc: 6.9236, Test Acc: 1.6698\n",
      "Epoch: 004, Train Acc: 6.9116, Test Acc: 1.6674\n",
      "Epoch: 005, Train Acc: 6.9051, Test Acc: 1.6663\n",
      "Epoch: 006, Train Acc: 6.9046, Test Acc: 1.6669\n",
      "Epoch: 007, Train Acc: 6.9090, Test Acc: 1.6681\n",
      "Epoch: 008, Train Acc: 6.9065, Test Acc: 1.6686\n",
      "Epoch: 009, Train Acc: 6.9074, Test Acc: 1.6681\n",
      "Epoch: 010, Train Acc: 6.9103, Test Acc: 1.6705\n",
      "Epoch: 011, Train Acc: 6.8380, Test Acc: 1.6461\n",
      "Epoch: 012, Train Acc: 6.9187, Test Acc: 1.6731\n",
      "Epoch: 013, Train Acc: 6.9225, Test Acc: 1.6763\n",
      "Epoch: 014, Train Acc: 6.9648, Test Acc: 1.6940\n",
      "Epoch: 015, Train Acc: 6.9375, Test Acc: 1.6826\n",
      "Epoch: 016, Train Acc: 6.9334, Test Acc: 1.6820\n",
      "Epoch: 017, Train Acc: 6.9338, Test Acc: 1.6821\n",
      "Epoch: 018, Train Acc: 6.9380, Test Acc: 1.6837\n",
      "Epoch: 019, Train Acc: 6.9421, Test Acc: 1.6853\n",
      "Epoch: 020, Train Acc: 6.9448, Test Acc: 1.6870\n",
      "Epoch: 021, Train Acc: 6.9383, Test Acc: 1.6866\n",
      "Epoch: 022, Train Acc: 6.9410, Test Acc: 1.6878\n",
      "Epoch: 023, Train Acc: 6.9417, Test Acc: 1.6884\n",
      "Epoch: 024, Train Acc: 6.9426, Test Acc: 1.6892\n",
      "Epoch: 025, Train Acc: 6.9417, Test Acc: 1.6881\n",
      "Epoch: 026, Train Acc: 6.9443, Test Acc: 1.6881\n",
      "Epoch: 027, Train Acc: 6.9441, Test Acc: 1.6909\n",
      "Epoch: 028, Train Acc: 6.9453, Test Acc: 1.6914\n",
      "Epoch: 029, Train Acc: 6.9464, Test Acc: 1.6924\n",
      "Epoch: 030, Train Acc: 6.9480, Test Acc: 1.6934\n",
      "Epoch: 031, Train Acc: 6.9466, Test Acc: 1.6930\n",
      "Epoch: 032, Train Acc: 6.9478, Test Acc: 1.6928\n",
      "Epoch: 033, Train Acc: 6.9485, Test Acc: 1.6938\n",
      "Epoch: 034, Train Acc: 6.9478, Test Acc: 1.6942\n",
      "Epoch: 035, Train Acc: 6.9534, Test Acc: 1.6966\n",
      "Epoch: 036, Train Acc: 6.9501, Test Acc: 1.6955\n",
      "Epoch: 037, Train Acc: 6.9508, Test Acc: 1.6963\n",
      "Epoch: 038, Train Acc: 6.9621, Test Acc: 1.6935\n",
      "Epoch: 039, Train Acc: 6.9372, Test Acc: 1.6911\n"
     ]
    }
   ],
   "source": [
    "model = PermInvariant(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(out, torch.tensor(data.betti_numbers,dtype=torch.float))  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    losses = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data)\n",
    "        \n",
    "        losses += criterion(out, torch.tensor(data.betti_numbers,dtype=torch.float))\n",
    "    return losses\n",
    "\n",
    "\n",
    "for epoch in range(1, 40):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(\n",
    "        f\"Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted incorrect 371\n",
      "predicted incorrect 79\n",
      "percentage correct 0.8244444444444444\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "losses = 0\n",
    "y_hat = []\n",
    "y = []\n",
    "for data in test_loader:  # Iterate in batches over the training/test dataset.\n",
    "    out = model(data)\n",
    "    y_hat.append(out.round().long())\n",
    "    y.append(torch.tensor(data.betti_numbers))\n",
    "\n",
    "y_hat = torch.vstack(y_hat)\n",
    "y = torch.vstack(y)\n",
    "\n",
    "\n",
    "incorrect = torch.count_nonzero(y-y_hat!=0).item()\n",
    "correct = torch.count_nonzero(y-y_hat==0).item()\n",
    "\n",
    "print(\"predicted incorrect\",correct)\n",
    "print(\"predicted incorrect\",incorrect)\n",
    "print(\"percentage correct\", correct / (correct + incorrect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 3, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 3, 0],\n",
       "        [1, 3, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 0, 1],\n",
       "        [1, 0, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 0, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 3, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 0, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 3, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
